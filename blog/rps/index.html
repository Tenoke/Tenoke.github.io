<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Building an in-browser Rock Paper Scissors Neural Network capable of beating humans | Svilen Todorov</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="Building an in-browser Rock Paper Scissors Neural Network capable of beating humans" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="As the New York Times have demonstrated, an algorithm can consistently win against humans at Rock Paper Scissors (RPS) using the right statistical techniques. The fact that it is doable, the simplicity, and the popularity of the game make it a good choice for attempting to do it using Deep Learning and making it run with tensorflow.js." />
<meta property="og:description" content="As the New York Times have demonstrated, an algorithm can consistently win against humans at Rock Paper Scissors (RPS) using the right statistical techniques. The fact that it is doable, the simplicity, and the popularity of the game make it a good choice for attempting to do it using Deep Learning and making it run with tensorflow.js." />
<link rel="canonical" href="https://svilentodorov.xyz//blog/rps/" />
<meta property="og:url" content="https://svilentodorov.xyz//blog/rps/" />
<meta property="og:site_name" content="Svilen Todorov" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-07-31T00:00:00+02:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","url":"https://svilentodorov.xyz//blog/rps/","headline":"Building an in-browser Rock Paper Scissors Neural Network capable of beating humans","dateModified":"2018-07-31T00:00:00+02:00","datePublished":"2018-07-31T00:00:00+02:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://svilentodorov.xyz//blog/rps/"},"description":"As the New York Times have demonstrated, an algorithm can consistently win against humans at Rock Paper Scissors (RPS) using the right statistical techniques. The fact that it is doable, the simplicity, and the popularity of the game make it a good choice for attempting to do it using Deep Learning and making it run with tensorflow.js.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css">
  <link rel="stylesheet" href="/static/thumb.css">
  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?"><link type="application/atom+xml" rel="alternate" href="https://svilentodorov.xyz//feed.xml" title="Svilen Todorov" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Svilen Todorov</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
            <a class="page-link" href="/rps"><span><img src="/static/previews/b912c32e013898b7.png"></span><span><img src="/static/previews/b912c32e013898b7.png"></span><span><img src="/static/previews/b912c32e013898b7.png"></span>RPS Demo</a>
            <a class="page-link" href="/blog"><span><img src="/static/previews/8caafe4386f95803.png"></span><span><img src="/static/previews/8caafe4386f95803.png"></span><span><img src="/static/previews/8caafe4386f95803.png"></span>Blog</a>
            <a class="page-link" href="/about"><span><img src="/static/previews/979bddc4a8caafdd.png"></span><span><img src="/static/previews/979bddc4a8caafdd.png"></span><span><img src="/static/previews/979bddc4a8caafdd.png"></span>About</a>
<!--<a class="page-link" href="/blog.html"><span><img src="/static/previews/58edaedca2ed47a8.png"></span><span><img src="/static/previews/58edaedca2ed47a8.png"></span>Blog</a><a class="page-link" href="/rps/"><span><img src="/static/previews/e28074f3e186f0ff.png"></span><span><img src="/static/previews/e28074f3e186f0ff.png"></span><span><img src="/static/previews/e28074f3e186f0ff.png"></span>RPS</a>-->
        </div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
  <center><h2 class="post-title p-name" itemprop="name headline">Building an in-browser Rock Paper Scissors Neural Network capable of beating humans</h1> 
  <h2 class="post-subtitle p-name" itemprop="name headline">Using keras and tensorflow.js</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2018-07-31T00:00:00+02:00" itemprop="datePublished">Jul 31, 2018
      </time></p>
    </center>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>As the <a href="https://archive.nytimes.com/www.nytimes.com/interactive/science/rock-paper-scissors.html"><span><img src="/static/previews/a42519d4a8d9ade7.png"></span><span><img src="/static/previews/a42519d4a8d9ade7.png"></span><span><img src="/static/previews/a42519d4a8d9ade7.png"></span>New York Times</a> have demonstrated, an algorithm can consistently win against humans at Rock Paper Scissors (RPS) using the right statistical techniques. The fact that it is doable, the simplicity, and the popularity of the game make it a good choice for attempting to do it using Deep Learning and making it run with tensorflow.js.</p>

<p>The goals here are simple - we want to run the Neural Net in the user’s browser, and we want it to have some edge and win against most humans.</p>

<h2 id="framing-the-problem">Framing the problem</h2>

<p>A common instinct when thinking of games is to have an agent-based approach using reinforcement learning - e.g. Q learning. However, reinforcement learning has a reputation for being somewhat finicky, unstable, and often relatively computationally expensive.</p>

<p>In this specific case, we can, however, frame the problem as a classification problem - predicting whether the next move by the human is going to be a Rock/Paper/Scissors and simply doing the opposite ourselves - which allows us to use somewhat more robust, standard and hopefully smaller models.</p>

<h2 id="preparing-to-build-the-model">Preparing to build the model</h2>

<p>We are going to be running the finished model fully in the browser and despite it being possible to define everything in JavaScript, some things are easier to do in python. For one, the tensorflow.js API is not quite as complete and nice as the python one, and even more importantly - I find preprocessing of data much easier in python and working in a Jupyter notebook in general.</p>

<p>Thus, we are going to take advantage of being able to import a tensorflow/keras model into tensorflow.js, which as far as I can tell is almost always the better option.</p>

<p>Note: The <a href="https://github.com/Tenoke/tensorflowjs-rps"><span><img src="/static/previews/e8e45eedf15bfd87.png"></span><span><img src="/static/previews/e8e45eedf15bfd87.png"></span><span><img src="/static/previews/e8e45eedf15bfd87.png"></span><span><img src="/static/previews/e8e45eedf15bfd87.png"></span><span><img src="/static/previews/e8e45eedf15bfd87.png"></span><span><img src="/static/previews/e8e45eedf15bfd87.png"></span>associated repo</a> has the code, data, and all pip-installable prerequisites.</p>

<h3 id="overview-of-approach">Overview of approach</h3>

<p>We are going to use an LSTM, so data from the previous moves made by the player can influence a prediction of their next move, while also being able to work with a non-fixed number of moves. After we predict their next move, we are simply going to do the move which wins against them (e.g. if we predict they are going to throw rock, we throw paper).</p>

<p>We are also going to use a little trick to counter how weak the signal in the data is. Even though humans don’t quite play randomly (if they did, we wouldn’t ever be able to perform better against anyone, except by chance) they hardly follow an exceptionally easy to spot pattern either. In fact, we should expect it to be fairly hard, and data-intensive for our model to spot a pattern and to even start learning anything at all about the data thrown at it.</p>

<p>What we are going to do, in order to force the model to at least initially learn <em>something</em> about RPS is to give it a secondary objective - to guess who won the current round (for which it has all the data), and to keep track of how many wins it has against the player overall. A fairly easy objective, compared to our main objective of guessing the player’s next move.</p>

<p>This has two benefits - it makes the model learn something about RPS (mainly which hand wins against which other hand), and it is also extremely helpful while building the model - if we see that it is not even learning the secondary objective, then there is little hope for it to learn the main one. Indeed, this helped me identify multiple bugs during development.</p>

<h3 id="imports">Imports</h3>

<p>Let’s start by importing the main things we need - numpy and keras.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from tensorflow import keras
import numpy as np
</code></pre></div></div>

<h3 id="data">Data</h3>

<p>I looked for any RPS data to build the initial model on, and the first thing which popped out and seemed usable was <a href="https://github.com/PizzaRollExpert/Rock-paper-scissors-data/"><span><img src="/static/previews/5d4651eeacc521f9.png"></span><span><img src="/static/previews/5d4651eeacc521f9.png"></span><span><img src="/static/previews/5d4651eeacc521f9.png"></span>This repo</a></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>%%bash
wget https://github.com/PizzaRollExpert/Rock-paper-scissors-data/raw/master/data.txt
</code></pre></div></div>

<p>After downloading it we need to create a dict for converting the symbols in the dataset to numbers.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>move_to_n = {
    's':1,
    'p':2,
    'x':3
}
</code></pre></div></div>

<p>We then create a function that iterates over all the moves in the files, converts them to numbers using the move_to_n dict, and splits all the moves that are part of the same game into arrays. The code can be simplified and sped up, but as it is for a one-time preprocessing of a very specifically formatted dataset, there’d be little point.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def convert_data(data):
    result = []
    game = []
    for row in data:
        moves = []
        if row == '-':
            if len(game) &gt; 2:
                result.append(np.array(game))
                game = []
            continue
        for move in row:
            moves.append(move_to_n[move])
        if len(moves) &gt; 1:
            game.append(np.array(moves))
        moves = []
    return np.array(result)
</code></pre></div></div>

<p>We then open the data we downloaded, split it by rows, convert it using our function, and then flip it - so we have the data both from the perspective of the first player (e.g. rock vs paper) and the second one (e.g. paper vs rock).</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>data = convert_data(data)
data2 = np.array([np.flip(games, 1) for games in data]) #reverse for player2
data = np.concatenate((data2, data))
</code></pre></div></div>

<p>Now we have our X - the prepared data for passing to the model to base its guesses, but we need to create our y (ground truth), too.</p>

<p>First, we are going to make a small helper function for determining who won a given round. I googled around for an easier way to check who won instead of <code class="highlighter-rouge">if player1 == 'rock' and player2 ==..</code>, and I created the function below, based on what I saw <a href="https://stackoverflow.com/questions/11377117/rock-paper-scissors-determine-win-loss-tie-using-math"><span><img src="/static/previews/94596c07c1f7e4fa.png"></span><span><img src="/static/previews/94596c07c1f7e4fa.png"></span><span><img src="/static/previews/94596c07c1f7e4fa.png"></span>Here</a>. I admit, I had to triple-check if it works properly.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def calculate_winner(x):
    result = x[0] - x[1]
    if result == 0: return 0 #tie
    if result in (1,-2): return 1 #win
    return -1 #lose
</code></pre></div></div>

<p>And then another function to create our matching X, and y. We go over each game (which has multiple moves by the same players), add a running score using <code class="highlighter-rouge">calculate_winner</code> for our secondary objective, and use next round’s move from player 1 as the portion of y in our primary objective.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def create_xy_winner(data):
    result_y = []
    result_x = []
    for game in data:
        game_y = []
        score = 0
        for i, moves in enumerate(game):
            if i+1 == len(game):
                result_y.append(np.array(game_y))
                result_x.append(game[:-1]) #remove last moves from x
                #skip last game as we dont know what player1 will choose next move
                continue
            score += calculate_winner(game[i])
            game_y.append([game[i+1][0], score]) #append next player1 move
    return np.array(result_x), np.array(result_y)

X, y = create_xy_winner(data)
</code></pre></div></div>

<h3 id="model">Model</h3>

<p>We have our data nicely formatted now, so it is time to create our model.</p>

<p>We start with an Input layer, which has dimensions (None, 8) - None for the timesteps (as many as we pass) which correspond to the rounds in a given game, and 8 because after playing with it, I realized that one-hot encoding our (e.g. Rock - Paper) input data works better after testing. 
We then add a Dense layer (Note: instead of one-hot encoding and Dense layer, we could’ve also just used an Embedding).
After that is our LSTM layer, which is the key to remembering and using information from previous rounds.
We then add two Dense layers in a row, with the second one outputting a probability representing whether we expect player 1 to throw, rock paper, or scissors.
We then do the same for our secondary objective - how many wins has player 1 had so far, which is a single number.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">main_input</span> <span class="p">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="p">=(</span><span class="n">None</span><span class="p">,</span><span class="m">8</span><span class="p">),</span> <span class="n">dtype</span><span class="p">=</span><span class="s1">'float32'</span><span class="p">)</span>
<span class="n">dense</span> <span class="p">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="m">32</span><span class="p">,</span> <span class="n">activation</span><span class="p">=</span><span class="s1">'relu'</span><span class="p">)(</span><span class="n">main_input</span><span class="p">)</span>
<span class="n">lstm</span> <span class="p">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="m">96</span><span class="p">,</span> <span class="n">return_sequences</span><span class="p">=</span><span class="nb">True</span><span class="p">)(</span><span class="n">dense</span><span class="p">)</span>
<span class="n">main_output</span> <span class="p">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="m">20</span><span class="p">,</span> <span class="n">activation</span><span class="p">=</span><span class="s1">'relu'</span><span class="p">)(</span><span class="n">lstm</span><span class="p">)</span>
<span class="n">main_output</span> <span class="p">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="m">4</span><span class="p">,</span> <span class="n">activation</span><span class="p">=</span><span class="s1">'softmax'</span><span class="p">)(</span><span class="n">main_output</span><span class="p">)</span>
<span class="n">second_output</span> <span class="p">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="m">20</span><span class="p">,</span> <span class="n">activation</span><span class="p">=</span><span class="s1">'tanh'</span><span class="p">)(</span><span class="n">lstm</span><span class="p">)</span>
<span class="n">second_output</span> <span class="p">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="m">1</span><span class="p">)(</span><span class="n">second_output</span><span class="p">)</span>
<span class="k">model</span> <span class="p">=</span> <span class="n">keras</span><span class="p">.</span><span class="k">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">=[</span><span class="n">main_input</span><span class="p">,],</span> <span class="n">outputs</span><span class="p">=[</span><span class="n">main_output</span><span class="p">,</span> <span class="n">second_output</span><span class="p">])</span>
</code></pre></div></div>

<p>We also create an optimizer - Adam with the normal defaults, and compile the model, so the primary objective is treated as much more important (1.0) than our secondary objective (0.2), and we choose their respective loss functions - categorical crossentropy for the primary (as we are choosing categories - rock, paper or scissors), and mean squared error for the number of wins.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>opt = keras.optimizers.Adam(lr=0.001)
model.compile(loss=['categorical_crossentropy', 'mse'], optimizer=opt, metrics=['accuracy'], loss_weights=[1., 0.2])
</code></pre></div></div>
<p>That’s it for the model. I also attempted some variations - adding Dropout, Batchnorm, and more/less layers, but the current implementation worked best out of those I tried.</p>

<h3 id="training">Training</h3>

<p>Now, is the time to train our model, however, I get an error when I try to model.fit the data - The model expects our data to be one-hot encoded (or more specifically to have a shape of *,8 rather than *,2), but I didn’t do that initially. Now, because we are working with so little data, and a tiny model (all of it trains in a few seconds on my CPU), we can just do it as we pass the data.</p>

<p>We iterate over all the games we have, one-hot encode our X and primary y, using the built-in keras function <code class="highlighter-rouge">to_categorical</code>, re-shape the data until we get it how the model expects it (I rarely get this quite right on the first try) and train the model using a batch size of 1.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    for i in range(len(X)):
        X_, y_ = X[i], y[i]
        X_ = keras.utils.to_categorical(X_, 4)
        X_ = X_.reshape(1, X_.shape[0], 8)
        y_1 = keras.utils.to_categorical(y_[:,0].reshape(1, y_.shape[0], 1), 4)
        y_2 = y_[:,1].reshape(1, y_.shape[0], 1)
        verbose = 2 if (i % 15 == 0) else 0 # print only 1/25th of the time
        model.fit(X_, [y_1, y_2], epochs=1, shuffle=False, batch_size=1, verbose=verbose)
</code></pre></div></div>

<p>Now, we have a trained model and it seems to reach an accuracy of 1 for guessing the number of wins (after fixing a couple of bugs), so we know the model is doing something right. After testing it out though, it will sometimes be very exploitable (e.g. getting stuck into throwing scissors 10 times in a row).</p>

<p>So, my next step was to increase the data we have - mainly by playing a bunch of games against it and then re-training by adding the new data in. After doing that, I sent it to 12 people, with only one of them managing to win (after at least 50 rounds), so I added their data to main data and re-trained it again.</p>

<p>Realistically, the model is somewhat overfitted against playing against me, as that is where the bulk of the data comes from - and it really does wipe the floor with me. If we truly want to optimize the model, we’d keep collecting more data from different people and keep training it, but it already seems to be able to win against most people (given a sufficient number of rounds) which is good enough for our purposes.</p>

<h3 id="exporting-the-model">Exporting the model</h3>

<p>Now that we have built and trained our model we just need to load it with tensorflow.js and make it work in the browser. We first export it.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import tensorflowjs as tfjs
tfjs.converters.save_keras_model(model, 'Full-Model')
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>%%bash
rm -rf static/Full-Model
mv Full-Model static/
</code></pre></div></div>

<h3 id="importing-the-model-to-javascript">Importing the model to JavaScript</h3>

<p>All we need in order to load our model is to import tensorflow.js, which we will do in our html via a CDN.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.11.2"&gt; &lt;/script&gt;
</code></pre></div></div>

<p>After that, we can simply load it in our JavaScript like so</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>const fullModel  = tf.loadModel('/static/Full-Model/model.json')
</code></pre></div></div>

<p><em>Note: A lot of things are still broken in tensorflow.js - for one, if you name your layers yourself, you can’t import the model. For another, it doesn’t support the default naming of the newest version of tensorflow either. If you have any problems, try using an older version of tensorflow, or tensorflow.js. When I had that issue, it was most easily fixed using <code class="highlighter-rouge">import keras</code> instead of <code class="highlighter-rouge">from tensorflow import keras</code>, with newest versions from pip/conda for both.</em></p>

<p>After we have loaded the model we create the dicts for converting from number to move, and back.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>n_to_move = {
  1:'rock',
  2:'paper',
  3:'scissors'
}

move_to_n = {
  'rock': 1,
  'paper': 2,
  'scissors': 3
}
</code></pre></div></div>

<p>We also choose a random first move (as we have no data yet) and create a list to hold the moves so far and some counters for the wins.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>function getRandomInt(max, starting=1) {
  return (starting + Math.floor(Math.random() * max))
}
//Choose a random first move
let nextComputerMove = getRandomInt(3)
currentMoves = []
let humanWinCounter = 0
let computerWinCounter = 0
let tieCounter = 0
</code></pre></div></div>

<p>We then create a copy of the <code class="highlighter-rouge">to_categorical</code> function we used for one-hot encoding the data, as it doesn’t exist in tensorflow.js, and a function to determine who has won (and update the win counters)</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>function to_categorical(n, length=4) {
  let result = Array.from({length}, ()=&gt; 0.)
  result[n] = 1.
  return result
}

function updateCounters(humanMove, computerMove) {
  switch (humanMove - computerMove) {
    case 0:
      tieCounter++
      return 0
    case  1: 
    case -2:
      humanWinCounter++
      return 1
    default:
      computerWinCounter++
      return 2
  }
}
</code></pre></div></div>

<p>We will also need a function to determine our move based on our prediction of the player’s next move (e.g. if we predict rock, throw paper)</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
function moveBasedOn(move) {
  switch(move) {
    case 1:
      return 2
    case 2:
      return 3
    case 3:
      return 1
  }
}
</code></pre></div></div>

<p>Now we can create a function, which uses the moves done by the player and computer so far, and uses the model to choose our next move. We only use the last 28 moves - I tried a few numbers between the last 20 and last 35 moves, and somewhere between 25 and 30 seemed to perform best in my limited testing, likely due to the nature of our training data in combination with LSTMs sometimes getting more brittle after a larger number of timesteps.</p>

<p>Tensorflow.js functions are mostly asynchronous (with some of them having a synchronous version like .dataSync), so any function which works with the model needs to be asynchronous, too.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">async</span> <span class="k">function</span> <span class="nf">calculateNextComputerMove</span><span class="p">()</span> <span class="p">{</span>
  <span class="k">const</span> <span class="no">model</span> <span class="o">=</span> <span class="k">await</span> <span class="nx">fullModel</span>
  <span class="nx">let</span> <span class="nx">lastMoves</span> <span class="o">=</span> <span class="nx">currentMoves</span><span class="o">.</span><span class="nx">slice</span><span class="p">(</span><span class="nx">Math</span><span class="o">.</span><span class="nb">max</span><span class="p">(</span><span class="nx">currentMoves</span><span class="o">.</span><span class="nx">length</span><span class="o">-</span><span class="mi">28</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="nx">currentMoves</span><span class="o">.</span><span class="nx">length</span><span class="p">)</span>
  <span class="nx">let</span> <span class="nx">data</span> <span class="o">=</span> <span class="nx">tf</span><span class="o">.</span><span class="nx">tensor3d</span><span class="p">([</span><span class="nx">lastMoves</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="nx">lastMoves</span><span class="o">.</span><span class="nx">length</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
  <span class="nx">let</span> <span class="nx">nextHumanMovePrediction</span> <span class="o">=</span> <span class="nx">model</span><span class="o">.</span><span class="nx">predict</span><span class="p">(</span><span class="nx">data</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nx">as1D</span><span class="p">()</span>
  <span class="c1">// we are getting predictions for all moves (because of how we trained the network)</span>
  <span class="c1">// but only care for the prediction for the next move - the last 4 numbers</span>
  <span class="nx">nextHumanMovePrediction</span> <span class="o">=</span> <span class="nx">nextHumanMovePrediction</span><span class="o">.</span><span class="nx">slice</span><span class="p">(</span><span class="nx">nextHumanMovePrediction</span><span class="o">.</span><span class="nx">shape</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
  <span class="c1">// next we turn that into a single number from a one-hot encoding</span>
  <span class="nx">nextHumanMovePrediction</span> <span class="o">=</span> <span class="nx">nextHumanMovePrediction</span><span class="o">.</span><span class="nx">argMax</span><span class="p">()</span><span class="o">.</span><span class="nx">dataSync</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
  <span class="c1">// and turn that into our next move based on what will beat the human</span>
  <span class="k">return</span> <span class="nx">moveBasedOn</span><span class="p">(</span><span class="nx">nextHumanMovePrediction</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>When we have that, all that is needed is a function that takes the player’s move, shows them the model’s move (which has been calculated before they even made theirs), updates the counters and uses the current data to calculate the model’s next move.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>function chooseMove(move) {
  console.log('human: ', n_to_move[move])
  var winner = updateCounters(move, nextComputerMove)
  console.log(winner) # 0 = tie, 1 = human, 2 = computer
  currentMoves.push(to_categorical(move).concat(to_categorical(nextComputerMove)))
  calculateNextComputerMove().then(nextMove=&gt;nextComputerMove=nextMove)
}
</code></pre></div></div>

<p>That’s it. You can now play against the model by opening the console in your browser, and calling chooseMove(..) with ‘rock’, ‘paper’ or ‘scissors’, or building a frontend around the model like the one in the <a href="https://github.com/Tenoke/tensorflowjs-rps"><span><img src="/static/previews/e8e45eedf15bfd87.png"></span><span><img src="/static/previews/e8e45eedf15bfd87.png"></span><span><img src="/static/previews/e8e45eedf15bfd87.png"></span><span><img src="/static/previews/e8e45eedf15bfd87.png"></span><span><img src="/static/previews/e8e45eedf15bfd87.png"></span><span><img src="/static/previews/e8e45eedf15bfd87.png"></span>github repo</a> accompanying this post.</p>

  </div><a class="u-url" href="/blog/rps/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">


    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Svilen Todorov</li><li><a class="u-email" href="mailto:sviltodorov@gmail.com">sviltodorov@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/tenoke"><span><img src="/static/previews/ed86ab8069dbb6ce.png"></span><span><img src="/static/previews/ed86ab8069dbb6ce.png"></span><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">tenoke</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Personal site for Data Scientist and Machine Learning Engineer - Svilen Todorov</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
